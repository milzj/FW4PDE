<div id="refs" class="references csl-bib-body hanging-indent">

<div id="ref-Alnes2015" class="csl-entry">

Alnæs, M. S., J Blechta, J. Hake, A Johansson, B Kehlet, A. Logg, C
Richardson, J Ring, M. E Rognes, and G. N. Wells. 2015. “The FEniCS
Project Version <span class="nodecor">1.5</span>.” *Arch. Numer.
Software* 3 (100): 9–23. <https://doi.org/10.11588/ans.2015.100.20553>.

</div>

<div id="ref-Besancon2022" class="csl-entry">

Besançon, Mathieu, Alejandro Carderera, and Sebastian Pokutta. 2022.
“FrankWolfe.jl: A High-Performance and Flexible Toolbox for Frank–Wolfe
Algorithms and Conditional Gradients.” *INFORMS Journal on Computing* 0
(0): null. <https://doi.org/10.1287/ijoc.2022.1191>.

</div>

<div id="ref-Demyanov1970" class="csl-entry">

Demyanov, Vladimir F., and Aleksandr M. Rubinov. 1970. *Approximate
Methods in Optimization Problems*. New York: Elsevier.

</div>

<div id="ref-Doikov2021" class="csl-entry">

Doikov, Nikita, and Yurii Nesterov. 2021. “Gradient Regularization of
Newton Method with Bregman Distances.” arXiv.
<https://doi.org/10.48550/ARXIV.2112.02952>.

</div>

<div id="ref-Dunn1980" class="csl-entry">

Dunn, J. C. 1980. “Convergence Rates for Conditional Gradient Sequences
Generated by Implicit Step Length Rules.” *SIAM J. Control Optim.* 18
(5): 473–87. <https://doi.org/10.1137/0318035>.

</div>

<div id="ref-Dunn1994" class="csl-entry">

———. 1994. “Gradient-Related Constrained Minimization Algorithms in
Function Spaces: Convergence Properties and Computational Implications.”
In *Large Scale Optimization*, edited by W. W. Hager, D. W. Hearn, and
P. M. Pardalos. Bosten: Springer.
<https://doi.org/10.1007/978-1-4613-3632-7_6>.

</div>

<div id="ref-Dunn1978" class="csl-entry">

Dunn, J. C., and S. Harshbarger. 1978. “Conditional Gradient Algorithms
with Open Loop Step Size Rules.” *J. Math. Anal. Appl.* 62 (2): 432–44.
<https://doi.org/10.1016/0022-247X(78)90137-3>.

</div>

<div id="ref-Harchaoui2015" class="csl-entry">

Harchaoui, Zaid, Anatoli Juditsky, and Arkadi Nemirovski. 2015.
“Conditional Gradient Algorithms for Norm-Regularized Smooth Convex
Optimization.” *Math. Program.* 152 (1-2, Ser. A): 75–112.
<https://doi.org/10.1007/s10107-014-0778-9>.

</div>

<div id="ref-Kunisch2021" class="csl-entry">

Kunisch, Karl, and Daniel Walter. 2021. “On Fast Convergence Rates for
Generalized Conditional Gradient Methods with Backtracking Stepsize,”
September. <http://arxiv.org/abs/2109.15217v1>.

</div>

<div id="ref-Mitusch2019" class="csl-entry">

Mitusch, Sebastian K., Simon W. Funke, and Jørgen S. Dokken. 2019.
“Dolfin-Adjoint 2018.1: Automated Adjoints for FEniCS and Firedrake.”
*J. Open Source Softw.* 4 (38): 1292.
<https://doi.org/10.21105/joss.01292>.

</div>

<div id="ref-Nordaas2016" class="csl-entry">

Nordaas, Magne, and Simon W. Funke. 2016. “The Moola Optimisation
Package.” Https://github.com/funsim/moola.

</div>

</div>
